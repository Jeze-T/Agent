# 大模型Agent 有哪些部分组成?
在基于 LLM 的智能体中，LLM 的充当着智能体的“大脑”的角色，同时还有 4 个关键部分：如下图所示，Agent 共由4个关键部分组成：
规划（Planning）
记忆（Memory）
工具（Tools）
行动（Action）
下面详细剖析： 

## 规划（Planning）
智能体会把大型任务分解为子任务，并规划执行任务的流程。智能体会对任务执行的过程进行思考和反思，决定是继续执行任务，或判断任务完结并终止运行。
大致分为两种类型：一种是不依赖反馈的计划，另一种则是基于反馈的计划。

不依赖反馈的计划
特点：
    不参考执行反馈：在计划制定和执行过程中，不依赖于任务执行后的即时反馈。
    预先确定：计划在执行前就已经完全确定，不随执行过程中的变化而调整。
常用策略：
   1、单路径推理：类似于决策树中的单路径探索，每一步都基于当前状态和预定规则或策略选择下一步行动，直到达到目标状态。
      优点：简单直接，计算量相对较小。
      缺点：对不确定性和动态变化的环境适应性差。
   2、多路径推理：生成多个可能的计划路径，并考虑不同路径之间的转换可能性。
      优点：灵活性高，能应对一定的不确定性。
      缺点：计算复杂度高，需要更多的计算资源。
   3、使用外部规划器：利用专门的规划算法（如A*、Dijkstra算法等）或规划系统（如HTN规划器）来搜索最优或可行的计划。
      优点：能够找到高质量的解决方案，适用于复杂问题。
      缺点：依赖于外部系统和算法的性能，可能需要大量的预处理和计算。

基于反馈的计划
特点：
    动态调整：根据任务执行过程中的实时反馈来动态调整计划。
    适应性强：能够很好地应对不确定性和动态变化的环境。
反馈来源：
    1、任务执行结果的客观反馈：如传感器数据、任务完成状态等。
    2、人的主观判断：在人类参与的任务中，根据人类的评价和指示来调整计划。
    3、辅助模型提供的反馈：通过模拟、预测或分析等手段生成的反馈，用于优化计划。
优势：提高系统在不确定性和复杂环境中的适应性和鲁棒性。能够更好地应对突发情况和意外事件。
挑战：需要实时处理和分析反馈数据，对系统的实时性要求较高。在高度动态和复杂的环境中，反馈可能不完全准确或存在延迟，增加了规划的难度。

## 记忆（Memory）
Memory在Agent系统中扮演重要角色，它存储和组织从环境中获取的信息，以指导未来行动。

结构划分
结构上，内存模块通常包含短期记忆和长期记忆两个部分。短期记忆暂存最近的感知，长期记忆存储重要信息供随时检索，详细介绍如下：
短期记忆：指在执行任务的过程中的上下文，会在子任务的执行过程产生和暂存，在任务完结后被清空；例如，记住一个电话号码直到拨打完毕。
长期记忆：指长时间保留的信息（为Agent提供保留和召回长期信息的能力），一般是指外部知识库，通常用向量数据库来存储和检索。长期记忆可以进一步分为显性记忆和隐性记忆。
          显性记忆，可以有意识地回忆和表达的信息，显性记忆又可以分为 情景记忆（个人经历的具体事件）和语义记忆（一般知识和概念）。
          隐性记忆，这种记忆通常是无意识的，涉及技能和习惯，如骑自行车或打字。

短期记忆和长期记忆的对比：
特性            短期记忆                                             长期记忆               
生命周期        对话或任务期间，短期有效                              跨对话和任务，长期有效
存储位置        内存、缓存、内存数据库、对话管理器上下文存储          关系型数据库、NoSQL、向量存储、知识图谱、对象存储
访问速度        快速访问（通常在内存中）                              稍慢（通常持久化存储在数据库）
数据类型        当前上下文、临时信息                                  用户偏好、历史记录、关系信息等
典型应用场景    多轮对话中的上下文追踪                                跨会话的个性化服务、个性偏好、长期用户信息
示例技术        Redis、内存数据库、对话管理上下文                     MySQL、MongoDB、FAISS、Neo4j、ES

格式划分
格式上，内存信息可以用自然语言表达，也可以编码为向量嵌入提高检索效率，还可以利用数据库存储，或组织为结构化列表表示内存语义。
1、自然语言：内存信息有时可以用自然语言表达，这种方式对于人类易于理解和解释，但在机器处理时可能效率较低。
2、向量嵌入：为了提高检索效率，内存信息常被编码为向量嵌入（Vector Embeddings）。向量嵌入能够将信息映射到高维空间中的点，通过计算点之间的距离来评估信息的相似度，从而实现高效的检索和匹配。
3、数据库和结构化列表：对于需要精确管理和高效查询的信息，可以使用数据库或结构化列表来组织内存。这种方式不仅便于信息的存储和检索，还能够清晰地表达内存信息的语义关系。

操作划分
操作上，主要通过记忆读取、写入和反射三种机制与环境交互。读取提取相关信息指导行动，写入存储重要信息，反射总结见解提升抽象水平。
1、记忆读取（Read）：Agent通过读取内存中的信息来提取相关知识，以指导其行动。以确保Agent能够获取到最相关和最有用的信息。
2、记忆写入（Write）：当Agent从环境中获取到新信息或学习到新知识时，它需要将这些信息写入到内存中。写入操作可以是对短期记忆的更新，也可以是将重要信息存储到长期记忆中，以便将来使用。
3、记忆反射（Reflection）：记忆反射是Agent对内存信息进行总结和抽象的过程。通过反思过去的经验和知识，Agent可以提炼出更高层次的见解和规律，从而提升其决策能力和适应性。这种过程类似于人类的反思和学习过程，是Agent实现智能的关键环节之一。

>参考：https://juejin.cn/post/7272558903102079012
我们现在通常使用向量数据库来存储、搜索外部记忆，它使用最大内积搜索(MIPS)的技术来对记忆进行相关性搜索，目前常用的MIPS 的算法有LSH、ANNOY、HNSW、FAISS、ScaNN等。

## 工具（Tools）
LLM 是数字世界中的程序，想要与现实世界互动、获取未知的知识，或是计算某个复杂的公式等，都离不开不工具。所以我们需要为智能体配备各种工具以及赋予它使用工具的能力。
为智能体配备工具 API，比如：计算器、搜索工具、日历、数据库查询工具、调用外部API获取额外信息、 也可以是函数（function）、软件开发工具包（sdk）、ChatPDF 解析文档插件、Midjourey 文生图多模态等。有了这些工具 API，智能体就可以是物理世界交互，解决实际的问题。
在智能体中，工具就是函数（Function），工具使用就是调用函数（Call Function）。在 LLM 中实现函数调用，使用到 LLM 的Function Calling能力。

Tools use
Function Calling是一种实现大型语言模型连接外部工具的机制。通过 API 调用 LLM 时，调用方可以描述函数，包括函数的功能描述、请求参数说明、响应参数说明，让 LLM 根据用户的输入，合适地选择调用哪个函数，同时理解用户的自然语言，并转换为调用函数的请求参数（通过 JSON 格式返回）。调用方使用 LLM 返回的函数名称和参数，调用函数并得到响应。最后，如果需求，把函数的响应传给 LLM，让 LLM 组织成自然语言回复用户。
function calling 具体工作流程如下图所示：

不同 LLM 的 API 接口协议会有所不同，【一文带你了解大模型——智能体（Agent）[8]】中详细展示了如何以OpenAI 的 API 协议为例，实现 Function Calling。下面简单的概述一下使用Function Calling需要的步骤：

1、函数描述【工具声明】
假设你的函数（可以自行编码实现，也可以通过调用外部 API 实现）已经被实现，我们需要向 LLM 描述这个函数，函数描述的必备要素：
函数名       函数的功能描述         函数的请求参数说明                函数的响应参数说明（可选）

2、调用 LLM 获得函数的请求参数【工具（集合）初始化】
Function Calling 是通过请求 LLM 的 chat API 实现的，在支持 Function Calling 模型的 chat API 参数中，会有一个 functions 参数 (或 tools，不同 LLM 的参数会有所不同) ，通过传入这个参数，大模型则会知道拥有哪些参数可供使用。并且会根据用户的输入，推理出应该调用哪些函数，并将自然语言转成函数的请求参数，返回给请求方。

3、调用函数【执行工具】
调用方获得 LLM 返回的函数调用信息（函数名称和调用参数）后，自行调用函数，并得到函数执行的响应。如果有需要，还可以把函数执行的响应追加到 chat API 的对话中传给 LLM，让 LLM 组织成自然语言回复用户。

除了使用Function calling，还有MRKL、Toolformer、HuggingGPT等方法。

目前的ChatGPT Plugins 和OpenAI API function calling 都是LLM使用工具的非常好的实践案例。除此之外，还有MRKL、TALM、Toolformer、HuggingGPT和API Bank等使用工具的方法。

## 行动（Action）
行动的职责是依规划与记忆，使用工具执行具体行动。包括与外部互动或工具调用，实现输入至输出的转化。比如：智能客服回复、查询天气预报、预约会议等。
将抽象的决策转化为具体的行动，它就像是一个桥梁，连接了Agent的内部世界与外部环境。在执行任务时，需要考虑行动的目标、生成方式、应用范围以及可能产生的影响。
理想的行动应当是有目的，例如完成特定任务、与其他代理进行交流或者探索环境。行动的产生可以依赖于查询过去的记忆经验，或者遵循预设的计划。而行动的范围，不仅可以通过利用如API和知识库等外部工具来扩展，还需要发挥大型语言模型（LLM）的内在能力，例如规划、对话及理解常识等。架构就像PC的硬件，但仅依赖架构设计是不够的，我们还需要赋予Agent完成不同任务的能力，这些被视为“软件”资源。
在https://arxiv.org/pdf/2308.11432[9]中提出了几种方法，包括模型微调、提示工程和机械工程。其中提示工程应该是最为常见的一种形式了，我们常听说的提示词工程师就是在这个语境下的角色。

1、模型微调：使用特定任务数据对模型进行微调，提升相关能力。数据可以来自人类注释、LLM生成或实际应用中收集。这可以使Agent行为更符合人类价值观。
2、提示工程，通过自然语言描述向LLM灌输所需的能力，然后将描述作为提示指导Agent操作。这可以让Agent快速获得指定的软件能力。
3、机械工程，主要涵盖：
   众包法：整合多个Agent的见解，形成更新的集体响应。
   试错法：Agent先执行操作，根据效果调整行动，逐步优化。
   经验积累法：Agent通过不断探索积累经验，逐步提升软件能力。
   自我驱动法：Agent自主设置目标并在环境中不断探索，最终获得软件能力。


## Agent的挑战
构建基于大型语言模型（LLM）的智能体是一个新兴领域，面临着众多挑战和限制。以下是几个主要的挑战及可能的解决方案：

角色适应性问题：智能体需要在特定领域内有效工作，对难以表征或迁移的角色，可以通过针对性地微调LLM来提高性能。这包括代表非常见角色或心理特征的能力提升。
上下文长度限制：有限的上下文长度限制了LLM的能力，尽管向量存储和检索提供了访问更大知识库的可能性。系统设计需要创新，以在有限的通信带宽内有效运作。
提示的鲁棒性：智能体的提示设计需要足够鲁棒，以防微小的变化导致可靠性问题。可能的解决方案包括自动优化调整提示或使用LLM自动生成提示。
知识边界的控制：控制LLM的内部知识，避免引入偏见或使用用户不知道的知识，是一个挑战。这要求智能体在处理信息时更加透明和可控。
效率和成本问题：LLM处理大量请求时的效率和成本是重要考量因素。优化推理速度和成本效率是提升多智能体系统性能的关键。

总的来说，基于LLM的智能体构建是一个复杂且多面的挑战，需要在多个方面进行创新和优化。持续的研究和技术发展对于克服这些挑战至关重要。
